---
title: "The Power of Efficiency"
format: 
  html:
    self-contained: true
editor: visual
---

-   The actual definition of efficiency is the ability to do or produce something while minimizing the amount of wasted resources or effort. But In relation to statistical computing and data science, I think efficiency means minimizing the amount of time/code used to complete a task, eliminating the repetition of code, creating code that is resistant to change in inputs, and using newer functions to complete a task in the easiest manner. Combining all these efficient processes allows you to eliminate the redundant and time-consuming processes involved in these two fields and better allocate your time generating analytics that help forward your goals. The whole goal of data science is to provide vaulable insights to make better decisions, and since efficiency allows you to do that faster, it's extremely important. I encountered efficiency for the first time when I was introduced to the across function in Lab 7 Task 1. Previously, I'd been duplicating code and changing arguments to apply functions to multiple columns. Intuitively, it seemed like there had to be a more concise way to apply those functions, so the introduction of the across function validated my suspicions and brought about my first "a-ha" moment. My second "a-ha" moment came towards the end of the quarter when we encountered functions in Lab 8. I'd had some previous experience with functions in Python and Julia, but had never applied them in a manner that was more efficient than just repeating code. My previous experience with functions had been teachers wanting to expose students to the idea of those concepts: Not show us the full capabilities of them. Once I was able to run the pluralize, phrase, and sing day functions in step four, I realized the power functions could have to reduce the amount of time spent on manipulating data. If one's able to write a function that's resistant to changes in input, they can apply complex processes to data with one line of code. The power of functions is exponential in statistical computing and data science. One of the more recent "a-ha" moments I had came about in another statistics course where my professor used R to run basic statistical functions, and forecast using popular auto regressive and moving average models. The professor, who I will keep unnamed, would give the class R files with the same equation repeated with different inputs for each separate example, and didn't use any modern tools and packages in any aspect of his code. The labs where we were used these R files became more of a challenge due to the excessive amount of time spent deciphering the code, rather than answering the lab questions. It made me realize that the simple use of a function from Lab 8 that could take different inputs for each time series model we were running could have reduced the amount code drastically. Even the use of the pipe operator to minimize the number of intermediate objects we had to create throughout the R file would have helped. In all, efficiency helps data scientist focus their time on producing the insights they were hired to provide, and when a data scientist has ways to eliminate time wasted on redundant processes they become much more valuable.
